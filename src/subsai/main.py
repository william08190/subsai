#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
SubsAI: Subtitles AI
Subtitles generation tool powered by OpenAI's Whisper and its variants.

This program is free software: you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation, either version 3 of the License, or (at your option) any later
version.
This program is distributed in the hope that it will be useful, but WITHOUT
ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
You should have received a copy of the GNU General Public License along with
this program. If not, see <https://www.gnu.org/licenses/>.
"""

import os
import pathlib
import tempfile
from typing import Union, Dict

import ffmpeg
import pysubs2
from dl_translate import TranslationModel
from pysubs2 import SSAFile
from subsai.configs import AVAILABLE_MODELS
from subsai.models.abstract_model import AbstractModel
from ffsubsync.ffsubsync import run, make_parser
from subsai.utils import available_translation_models

__author__ = "abdeladim-s"
__contact__ = "https://github.com/abdeladim-s"
__copyright__ = "Copyright 2023,"
__license__ = "GPLv3"
__github__ = "https://github.com/abdeladim/subsai"


class SubsAI:
    """
    Subs AI class

    Example usage:
    ```python
    file = './assets/test1.mp4'
    subs_ai = SubsAI()
    model = subs_ai.create_model('openai/whisper', {'model_type': 'base'})
    subs = subs_ai.transcribe(file, model)
    subs.save('test1.srt')
    ```
    """

    @staticmethod
    def available_models() -> list:
        """
        Returns the supported models

        :return: list of available models
        """
        return list(AVAILABLE_MODELS.keys())

    @staticmethod
    def model_info(model: str) -> dict:
        """
        Returns general infos about the model (brief description and url)

        :param model: model name

        :return: dict of infos
        """
        return {'description': AVAILABLE_MODELS[model]['description'],
                'url': AVAILABLE_MODELS[model]['url']}

    @staticmethod
    def config_schema(model: str) -> dict:
        """
        Returns the configs associated with a model

        :param model: model name

        :return: dict of configs
        """
        return AVAILABLE_MODELS[model]['config_schema']

    @staticmethod
    def create_model(model_name: str, model_config: dict = {}) -> AbstractModel:
        """
        Returns a model instance

        :param model_name: the name of the model
        :param model_config: the configuration dict

        :return: the model instance
        """
        return AVAILABLE_MODELS[model_name]['class'](model_config)

    @staticmethod
    def transcribe(media_file: str, model: Union[AbstractModel, str], model_config: dict = {}) -> SSAFile:
        """
        Takes the model instance (created by :func:`create_model`) or the model name.
        Returns a :class:`pysubs2.SSAFile` <https://pysubs2.readthedocs.io/en/latest/api-reference.html#ssafile-a-subtitle-file>`_

        :param media_file: path of the media file (video/audio)
        :param model: model instance or model name
        :param model_config: model configs' dict

        :return: SSAFile: list of subtitles
        """
        if type(model) == str:
            stt_model = SubsAI.create_model(model, model_config)
        else:
            stt_model = model
        media_file = str(pathlib.Path(media_file).resolve())
        return stt_model.transcribe(media_file)


class Tools:
    """
    Some tools related to subtitles processing (ex: translation)
    """

    def __init__(self):
        pass

    @staticmethod
    def available_translation_models() -> list:
        """
        Returns available translation models
        A simple link to :func:`utils.available_translation_models` for easy access

        :return: list of available models
        """

        return available_translation_models()

    @staticmethod
    def available_translation_languages(model: Union[str, TranslationModel]) -> list:
        """
        Returns the languages supported by the translation model

        :param model: the name of the model
        :return: list of available languages
        """
        if type(model) == str:
            langs = Tools.create_translation_model(model).available_languages()
        else:
            langs = model.available_languages()
        return langs

    @staticmethod
    def create_translation_model(model_name: str = "m2m100", model_family: str = None) -> TranslationModel:
        """
        Creates and returns a translation model instance.

        :param model_name: name of the model. To get available models use :func:`available_translation_models`
        :param model_family: Either "mbart50" or "m2m100". By default, See `dl-translate` docs
        :return: A translation model instance
        """
        mt = TranslationModel(model_or_path=model_name, model_family=model_family)
        return mt

    @staticmethod
    def translate(subs: SSAFile,
                  source_language: str,
                  target_language: str,
                  model: Union[str, TranslationModel] = "m2m100",
                  model_family: str = None,
                  translation_configs: dict = {}) -> SSAFile:
        """
        Translates a subtitles `SSAFile` object, what :func:`SubsAI.transcribe` is returning

        :param subs: `SSAFile` object
        :param source_language: the language of the subtitles
        :param target_language: the target language
        :param model: the translation model, either an `str` or the model instance created by
                        :func:`create_translation_model`
        :param model_family: Either "mbart50" or "m2m100". By default, See `dl-translate` docs
        :param translation_configs: dict of translation configs (see :attr:`configs.ADVANCED_TOOLS_CONFIGS`)

        :return: returns an `SSAFile` subtitles translated to the target language
        """
        if type(model) == str:
            translation_model = Tools.create_translation_model(model_name=model, model_family=model_family)
        else:
            translation_model = model

        translated_subs = SSAFile()
        for sub in subs:
            translated_sub = sub.copy()
            translated_sub.text = translation_model.translate(text=sub.text,
                                                              source=source_language,
                                                              target=target_language,
                                                              batch_size=translation_configs[
                                                                  'batch_size'] if 'batch_size' in translation_configs else 32,
                                                              verbose=translation_configs[
                                                                  'verbose'] if 'verbose' in translation_configs else False)
            translated_subs.append(translated_sub)
        return translated_subs

    @staticmethod
    def auto_sync(subs: SSAFile,
                  media_file: str,
                  **kwargs
                  ) -> SSAFile:
        """
        Uses (ffsubsync)[https://github.com/smacke/ffsubsync] to auto-sync subtitles to the media file

        :param subs: `SSAFile` file
        :param media_file: path of the media_file
        :param kwargs: configs to pass to ffsubsync (see :attr:`configs.ADVANCED_TOOLS_CONFIGS`)

        :return: `SSAFile` auto-synced
        """
        parser = make_parser()
        srtin_file = tempfile.NamedTemporaryFile(delete=False)
        srtout_file = tempfile.NamedTemporaryFile(delete=False)
        try:
            srtin = srtin_file.name + '.ass'
            srtout = srtout_file.name + '.srt'
            subs.save(srtin)
            cmd = [media_file,
                   '-i', srtin,
                   '-o', srtout]
            for config_name in kwargs:
                value = kwargs[config_name]
                if value is None or value is False:
                    continue
                elif type(value) == bool and value is True:
                    cmd.append(f'--{config_name}')
                else:
                    cmd.append(f'--{config_name}')
                    cmd.append(f'{value}')
            parsed_args = parser.parse_args(cmd)
            retval = run(parsed_args)["retval"]
            synced_subs = pysubs2.load(srtout)
            return synced_subs
        finally:
            srtin_file.close()
            os.unlink(srtin_file.name)
            srtout_file.close()
            os.unlink(srtout_file.name)
    @staticmethod
    def merge_subs_with_video(subs: Dict[str, SSAFile],
                  media_file: str,
                  output_filename: str = None,
                  **kwargs
                  ) -> str:
        """
        Uses ffmpeg to merge subtitles into a video media file.
        You cna merge multiple subs at the same time providing a dict with (lang,`SSAFile` object) key,value pairs
        Example:
        ```python
            file = '../../assets/video/test1.webm'
            subs_ai = SubsAI()
            model = subs_ai.create_model('openai/whisper', {'model_type': 'tiny'})
            en_subs = subs_ai.transcribe(file, model)
            ar_subs = pysubs2.load('../../assets/video/test0-ar.srt')
            Tools.merge_subs_with_video({'English': subs, "Arabic": subs2}, file)
        ```

        :param subs: dict with (lang,`SSAFile` object) key,value pairs
        :param media_file: path of the video media_file
        :param output_filename: Output file name (without the extension as it will be inferred from the media file)

        :return: Absolute path of the output file
        """
        import logging
        logger = logging.getLogger(__name__)

        metadata = ffmpeg.probe(media_file, select_streams="v")['streams'][0]
        assert metadata['codec_type'] == 'video', f'File {media_file} is not a video'

        logger.info(f"ğŸ¬ å¼€å§‹åˆå¹¶å­—å¹•åˆ°è§†é¢‘: {media_file}")
        logger.info(f"ğŸ“ å­—å¹•è¯­è¨€æ•°é‡: {len(subs)}")

        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶å­—å…¸ï¼Œå­˜å‚¨æ–‡ä»¶è·¯å¾„è€Œä¸æ˜¯æ–‡ä»¶å¥æŸ„
        srtin_files = {}
        for key in subs:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¹¶ç«‹å³å…³é—­ï¼Œåªä¿ç•™è·¯å¾„
            temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.srt', delete=False, encoding='utf-8')
            temp_file.close()
            srtin_files[key] = temp_file.name
            logger.info(f"ğŸ“„ åˆ›å»ºä¸´æ—¶æ–‡ä»¶: {key} -> {temp_file.name}")

        try:
            in_file = pathlib.Path(media_file)
            if output_filename is not None:
                # ä¿æŒè¾“å…¥æ–‡ä»¶çš„æ‰©å±•å
                out_file = in_file.parent / f"{output_filename}{in_file.suffix}"
            else:
                out_file = in_file.parent / f"{in_file.stem}-subs-merged{in_file.suffix}"

            video = str(in_file.resolve())

            # æ£€æµ‹è§†é¢‘ç¼–ç å™¨å’Œå®¹å™¨æ ¼å¼
            video_codec = metadata['codec_name']
            logger.info(f"ğŸ¥ æ£€æµ‹åˆ°è§†é¢‘ç¼–ç å™¨: {video_codec}")

            # æ ¹æ®è¾“å…¥æ ¼å¼é€‰æ‹©åˆé€‚çš„å­—å¹•ç¼–ç å™¨
            # WebMä½¿ç”¨webvtt,MP4ä½¿ç”¨mov_text
            if in_file.suffix.lower() in ['.webm', '.mkv']:
                # WebM/MKVå®¹å™¨ä½¿ç”¨webvttå­—å¹•
                metadata_subs = {'scodec': 'webvtt'}
                logger.info(f"ğŸ“¦ WebM/MKVå®¹å™¨ -> ä½¿ç”¨webvttå­—å¹•")
            elif metadata['codec_name'] == 'h264':
                # H264è§†é¢‘ä½¿ç”¨mov_textå­—å¹•
                metadata_subs = {'scodec': 'mov_text'}
                logger.info(f"ğŸ“¦ H264è§†é¢‘ -> ä½¿ç”¨mov_textå­—å¹•")
            else:
                # å…¶ä»–æ ¼å¼ï¼Œå°è¯•ä½¿ç”¨srt
                metadata_subs = {}
                logger.info(f"ğŸ“¦ å…¶ä»–æ ¼å¼ -> ä½¿ç”¨é»˜è®¤å­—å¹•ç¼–ç ")

            ffmpeg_subs_inputs = []

            for i, lang in enumerate(srtin_files):
                srtin = srtin_files[lang]

                # ä¿å­˜å­—å¹•åˆ°ä¸´æ—¶æ–‡ä»¶
                logger.info(f"ğŸ’¾ ä¿å­˜å­—å¹• '{lang}' åˆ°: {srtin}")
                subs[lang].save(srtin)

                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„è¢«å†™å…¥
                if os.path.exists(srtin):
                    file_size = os.path.getsize(srtin)
                    logger.info(f"âœ… å­—å¹•æ–‡ä»¶å·²åˆ›å»ºï¼Œå¤§å°: {file_size} å­—èŠ‚")

                    # è¯»å–å‰100ä¸ªå­—ç¬¦ç”¨äºè°ƒè¯•
                    with open(srtin, 'r', encoding='utf-8') as f:
                        preview = f.read(100)
                        logger.info(f"ğŸ“– æ–‡ä»¶å†…å®¹é¢„è§ˆ: {preview[:50]}...")
                else:
                    logger.error(f"âŒ å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨: {srtin}")

                ffmpeg_subs_inputs.append(ffmpeg.input(srtin)['s'])
                metadata_subs[f'metadata:s:s:{i}'] = "title=" + lang

            output_file = str(out_file.resolve())
            input_ffmpeg = ffmpeg.input(video)
            input_video = input_ffmpeg['v']
            input_audio = input_ffmpeg['a']

            # ä½¿ç”¨copyæ¨¡å¼ï¼Œä¸é‡æ–°ç¼–ç ï¼Œä¿æŒåŸæ ¼å¼
            logger.info(f"âœ… ä½¿ç”¨copyæ¨¡å¼ï¼Œä¿æŒåŸè§†é¢‘éŸ³é¢‘æ ¼å¼")
            output_ffmpeg = ffmpeg.output(
                input_video, input_audio, *ffmpeg_subs_inputs, output_file,
                vcodec='copy',
                acodec='copy',
                **metadata_subs
            )
            output_ffmpeg = ffmpeg.overwrite_output(output_ffmpeg)

            # æ‰“å°ffmpegå‘½ä»¤ç”¨äºè°ƒè¯•
            cmd = ffmpeg.compile(output_ffmpeg)
            logger.info(f"ğŸ¬ æ‰§è¡Œffmpegå‘½ä»¤: {' '.join(cmd)}")

            # æ•è·ffmpegè¾“å‡º
            try:
                stdout, stderr = ffmpeg.run(output_ffmpeg, capture_stdout=True, capture_stderr=True)
                logger.info(f"âœ… ffmpegæ‰§è¡ŒæˆåŠŸ")
                if stderr:
                    logger.debug(f"ffmpeg stderr: {stderr.decode('utf-8', errors='ignore')[-500:]}")
            except ffmpeg.Error as e:
                logger.error(f"âŒ ffmpegæ‰§è¡Œå¤±è´¥: {e.stderr.decode('utf-8', errors='ignore')}")
                raise

        finally:
            # æ¸…ç†ä¸´æ—¶å­—å¹•æ–‡ä»¶
            for srtin_path in srtin_files.values():
                if os.path.exists(srtin_path):
                    logger.info(f"ğŸ—‘ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {srtin_path}")
                    os.unlink(srtin_path)

        logger.info(f"ğŸ‰ å­—å¹•åˆå¹¶å®Œæˆ: {out_file.resolve()}")
        return str(out_file.resolve())

    @staticmethod
    def burn_karaoke_subtitles(subs: SSAFile,
                               media_file: str,
                               output_filename: str = None,
                               video_codec: str = 'libx264',
                               crf: int = 18,
                               preset: str = 'medium',
                               aspect_ratio: str = None,
                               min_resolution: int = 1080,
                               enable_uniqueness: bool = True,
                               uniqueness_index: int = 0) -> str:
        """
        Uses ffmpeg to burn ASS karaoke subtitles into video as hardcoded subtitles.
        This method preserves ASS karaoke effects (\\k tags) and includes advanced features:
        - Automatic upscaling to minimum resolution (default 1080p+)
        - Video uniqueness processing to avoid platform batch detection
        - Metadata randomization and cleanup
        - Quality optimization with configurable CRF and preset

        Example:
        ```python
            from subsai import Tools
            from subsai.karaoke_generator import create_karaoke_subtitles

            # Generate karaoke subtitles
            karaoke_subs = create_karaoke_subtitles(original_subs, style_name='classic')

            # Burn to video with full enhancement
            output = Tools.burn_karaoke_subtitles(
                karaoke_subs, 'input.mp4', 'output_karaoke',
                aspect_ratio='9:16',
                min_resolution=1080,
                enable_uniqueness=True
            )
        ```

        :param subs: SSAFile object with ASS karaoke subtitles
        :param media_file: path of the video file
        :param output_filename: Output file name (without extension)
        :param video_codec: Video codec for encoding (default: libx264)
        :param crf: Constant Rate Factor for quality (default: 18, range 0-51, lower = better quality, will be randomized if uniqueness enabled)
        :param preset: Encoding speed preset (default: medium, will be randomized if uniqueness enabled)
        :param aspect_ratio: Target aspect ratio for cropping (e.g., '16:9', '9:16', '4:3', '1:1', None=original)
        :param min_resolution: Minimum output height in pixels (default: 1080). Video will be upscaled if needed.
        :param enable_uniqueness: Enable video uniqueness processing to avoid platform batch detection (default: True)
        :param uniqueness_index: Index for batch processing to ensure different randomization per video (default: 0)

        :return: Absolute path of the output file
        """
        import logging
        import subprocess
        from subsai.video_uniqueness import (
            calculate_uniqueness_params,
            get_resolution_scale_params,
            build_uniqueness_filters,
            build_x264_params
        )

        logger = logging.getLogger(__name__)

        logger.info(f"ğŸ¤ å¼€å§‹çƒ§å½•å¡æ‹‰OKå­—å¹•: {media_file}")
        if aspect_ratio:
            logger.info(f"ğŸ“ ç›®æ ‡å®½é«˜æ¯”: {aspect_ratio}")
        if enable_uniqueness:
            logger.info(f"ğŸ² å¯ç”¨å”¯ä¸€æ€§å¢å¼º (ç´¢å¼•: {uniqueness_index})")

        metadata = ffmpeg.probe(media_file, select_streams="v")['streams'][0]
        assert metadata['codec_type'] == 'video', f'File {media_file} is not a video'

        # Get original video dimensions
        original_width = int(metadata['width'])
        original_height = int(metadata['height'])

        # Check for rotation metadata (common in mobile videos)
        # Some videos have rotation tags that swap width/height
        rotation = 0
        if 'tags' in metadata:
            if 'rotate' in metadata['tags']:
                rotation = int(metadata['tags']['rotate'])
        elif 'side_data_list' in metadata:
            for side_data in metadata['side_data_list']:
                if side_data.get('side_data_type') == 'Display Matrix' and 'rotation' in side_data:
                    rotation = int(side_data['rotation'])
                    break

        # If video is rotated 90 or 270 degrees, swap width and height
        if rotation in [90, -90, 270, -270]:
            original_width, original_height = original_height, original_width
            logger.info(f"ğŸ”„ æ£€æµ‹åˆ°è§†é¢‘æ—‹è½¬ {rotation}Â°, äº¤æ¢å®½é«˜")

        logger.info(f"ğŸ“º åŸå§‹è§†é¢‘å°ºå¯¸: {original_width}x{original_height}")

        # Calculate resolution scaling if needed
        scale_params = get_resolution_scale_params(original_width, original_height, min_resolution)
        if scale_params['need_scale']:
            logger.info(f"ğŸ” åˆ†è¾¨ç‡å‡çº§: {original_width}x{original_height} -> {scale_params['target_width']}x{scale_params['target_height']}")
        else:
            logger.info(f"âœ… åˆ†è¾¨ç‡å·²æ»¡è¶³è¦æ±‚: {original_height}p")

        # Calculate uniqueness parameters if enabled
        uniqueness_params = None
        if enable_uniqueness:
            uniqueness_params = calculate_uniqueness_params(media_file, uniqueness_index)
            logger.info(f"ğŸ² å”¯ä¸€æ€§å‚æ•°:")
            logger.info(f"  - CRF: {uniqueness_params['crf']}")
            logger.info(f"  - é¢„è®¾: {uniqueness_params['preset']}")
            logger.info(f"  - é¥±å’Œåº¦: {uniqueness_params['saturation']:.4f}")
            logger.info(f"  - äº®åº¦è°ƒæ•´: {uniqueness_params['brightness']:.4f}")
            logger.info(f"  - å¯¹æ¯”åº¦: {uniqueness_params['contrast']:.4f}")
            logger.info(f"  - å™ªå£°å¼ºåº¦: {uniqueness_params['noise_strength']:.4f}")
            logger.info(f"  - éŸ³é¢‘æ¯”ç‰¹ç‡: {uniqueness_params['audio_bitrate']}")
            logger.info(f"  - éŸ³é¢‘é‡‡æ ·ç‡: {uniqueness_params['audio_sample_rate']}Hz")
            logger.info(f"  - åˆ›å»ºæ—¶é—´: {uniqueness_params['metadata']['creation_time']}")
            logger.info(f"  - ç¼–ç å™¨: {uniqueness_params['metadata']['encoder']}")

            # Override CRF and preset from uniqueness params
            crf = uniqueness_params['crf']
            preset = uniqueness_params['preset']

        # Calculate crop parameters if aspect ratio is specified
        crop_filter = None
        if aspect_ratio and aspect_ratio.lower() != 'original':
            try:
                # Parse target aspect ratio
                target_w, target_h = map(int, aspect_ratio.split(':'))
                target_ratio = target_w / target_h

                # Use scaled dimensions for crop calculation if scaling is enabled
                # This ensures crop works on the final scaled resolution
                if scale_params['need_scale']:
                    base_width = scale_params['target_width']
                    base_height = scale_params['target_height']
                    logger.info(f"ğŸ¯ åŸºäºç¼©æ”¾åå°ºå¯¸è®¡ç®—è£å‰ª: {base_width}x{base_height}")
                else:
                    base_width = original_width
                    base_height = original_height

                base_ratio = base_width / base_height
                logger.info(f"ğŸ¯ ç›®æ ‡å®½é«˜æ¯”: {target_ratio:.3f} (å½“å‰: {base_ratio:.3f})")

                # Check if aspect ratio already matches (with 1% tolerance)
                ratio_diff = abs(base_ratio - target_ratio) / target_ratio
                if ratio_diff < 0.01:
                    logger.info(f"âœ… å®½é«˜æ¯”å·²åŒ¹é…ç›®æ ‡ {aspect_ratio}ï¼Œæ— éœ€è£å‰ª")
                    # Skip crop, aspect ratio already matches
                    crop_filter = None
                else:
                    # Calculate target standard dimensions
                    # Step 1: Calculate ideal target size based on aspect ratio and min_resolution
                    if base_ratio > target_ratio:
                        # Video is wider, base short side on width
                        ideal_width = min_resolution
                        ideal_height = int(min_resolution / target_ratio)
                    else:
                        # Video is taller or same, base short side on height
                        ideal_height = min_resolution
                        ideal_width = int(min_resolution * target_ratio)

                    # Ensure even dimensions
                    ideal_width = ideal_width - (ideal_width % 2)
                    ideal_height = ideal_height - (ideal_height % 2)

                    logger.info(f"ğŸ“ ç†æƒ³æ ‡å‡†å°ºå¯¸: {ideal_width}x{ideal_height}")

                    # Step 2: Check if current base size can accommodate the ideal target
                    min_side = min(base_width, base_height)
                    if base_width >= ideal_width and base_height >= ideal_height and min_side >= min_resolution:
                        # Current size is large enough, can crop to ideal size
                        target_crop_width = ideal_width
                        target_crop_height = ideal_height

                        # Check if crop is needed (dimensions differ from base)
                        if target_crop_width != base_width or target_crop_height != base_height:
                            # Validate crop dimensions
                            if target_crop_width > base_width or target_crop_height > base_height:
                                logger.warning(f"âš ï¸  è£å‰ªå°ºå¯¸({target_crop_width}x{target_crop_height})è¶…å‡ºè§†é¢‘å°ºå¯¸({base_width}x{base_height})ï¼Œå°†è¿›è¡Œé¢å¤–ç¼©æ”¾")
                                # Need additional scaling
                                scale_x = target_crop_width / base_width if target_crop_width > base_width else 1.0
                                scale_y = target_crop_height / base_height if target_crop_height > base_height else 1.0
                                additional_scale = max(scale_x, scale_y)

                                new_width = int(base_width * additional_scale)
                                new_height = int(base_height * additional_scale)
                                new_width = new_width - (new_width % 2)
                                new_height = new_height - (new_height % 2)

                                # Update scale params
                                scale_params = {
                                    'need_scale': True,
                                    'target_width': new_width,
                                    'target_height': new_height,
                                    'scale_filter': f"scale={new_width}:{new_height}:flags=lanczos"
                                }
                                base_width = new_width
                                base_height = new_height
                                logger.info(f"ğŸ”„ é¢å¤–ç¼©æ”¾åˆ°: {base_width}x{base_height}")

                            # Calculate crop position (center crop)
                            crop_x = (base_width - target_crop_width) // 2
                            crop_y = (base_height - target_crop_height) // 2

                            crop_filter = f"crop={target_crop_width}:{target_crop_height}:{crop_x}:{crop_y}"
                            logger.info(f"âœ‚ï¸  è£å‰ªåˆ°æ ‡å‡†å°ºå¯¸: {crop_filter} (è¾“å‡º: {target_crop_width}x{target_crop_height})")
                        else:
                            logger.info(f"âœ… å°ºå¯¸å·²æ˜¯æ ‡å‡†å°ºå¯¸ï¼Œæ— éœ€è£å‰ª: {base_width}x{base_height}")
                    else:
                        logger.warning(f"âš ï¸  å½“å‰å°ºå¯¸({base_width}x{base_height})ä¸è¶³ä»¥è£å‰ªåˆ°æ ‡å‡†å°ºå¯¸({ideal_width}x{ideal_height})ï¼Œå°†ç›´æ¥ç¼©æ”¾åˆ°ç›®æ ‡å°ºå¯¸")
                        # Directly scale to exact target dimensions, no crop needed
                        # This avoids potential crop coordinate errors when dimensions are very close
                        scale_params = {
                            'need_scale': True,
                            'target_width': ideal_width,
                            'target_height': ideal_height,
                            'scale_filter': f"scale={ideal_width}:{ideal_height}:flags=lanczos"
                        }
                        base_width = ideal_width
                        base_height = ideal_height
                        logger.info(f"ğŸ¯ ç›´æ¥ç¼©æ”¾åˆ°æ ‡å‡†å°ºå¯¸: {ideal_width}x{ideal_height}")
                        logger.info(f"âœ… æ— éœ€è£å‰ªï¼Œå·²è¾¾åˆ°ç²¾ç¡®ç›®æ ‡å°ºå¯¸")
                        crop_filter = None
            except (ValueError, ZeroDivisionError) as e:
                logger.warning(f"âš ï¸  æ— æ•ˆçš„å®½é«˜æ¯”æ ¼å¼ '{aspect_ratio}'ï¼Œå°†ä½¿ç”¨åŸå§‹å°ºå¯¸: {e}")
                crop_filter = None

        # Create temporary ASS file
        ass_temp = tempfile.NamedTemporaryFile(mode='w', suffix='.ass', delete=False, encoding='utf-8')

        try:
            # Save subtitles as ASS format to preserve karaoke effects
            logger.info(f"ğŸ“„ åˆ›å»ºä¸´æ—¶ASSæ–‡ä»¶: {ass_temp.name}")
            subs.save(ass_temp.name)
            ass_temp.close()

            # æ£€æŸ¥ASSæ–‡ä»¶
            if os.path.exists(ass_temp.name):
                file_size = os.path.getsize(ass_temp.name)
                logger.info(f"âœ… ASSæ–‡ä»¶å·²åˆ›å»ºï¼Œå¤§å°: {file_size} å­—èŠ‚")

                # è¯»å–å‰200ä¸ªå­—ç¬¦ç”¨äºè°ƒè¯•
                with open(ass_temp.name, 'r', encoding='utf-8') as f:
                    preview = f.read(200)
                    logger.info(f"ğŸ“– ASSæ–‡ä»¶å†…å®¹é¢„è§ˆ:\n{preview[:150]}...")
            else:
                logger.error(f"âŒ ASSæ–‡ä»¶ä¸å­˜åœ¨: {ass_temp.name}")

            in_file = pathlib.Path(media_file)
            if output_filename is not None:
                out_file = in_file.parent / f"{output_filename}{in_file.suffix}"
            else:
                out_file = in_file.parent / f"{in_file.stem}-karaoke{in_file.suffix}"

            output_file = str(out_file.resolve())

            # Build video filter chain
            if enable_uniqueness:
                # Use enhanced filter chain with uniqueness processing
                video_filter = build_uniqueness_filters(
                    uniqueness_params,
                    scale_params if scale_params['need_scale'] else None,
                    crop_filter,
                    ass_temp.name
                )
            else:
                # Use basic filter chain without uniqueness
                filters = []
                if scale_params['need_scale']:
                    filters.append(scale_params['scale_filter'])
                if crop_filter:
                    filters.append(crop_filter)
                filters.append(f"ass={ass_temp.name}")
                video_filter = ",".join(filters)

            logger.info(f"ğŸ¨ è§†é¢‘æ»¤é•œé“¾: {video_filter}")

            # Construct ffmpeg command
            ffmpeg_cmd = [
                '/usr/bin/ffmpeg',
                '-i', media_file,
                '-vf', video_filter,
                '-c:v', video_codec,
                '-crf', str(crf),
                '-preset', preset,
            ]

            # Add x264 parameters if uniqueness is enabled
            if enable_uniqueness:
                x264_params_str = build_x264_params(uniqueness_params)
                ffmpeg_cmd.extend(['-x264-params', x264_params_str])
                logger.info(f"ğŸ”§ x264å‚æ•°: {x264_params_str}")

                # Re-encode audio with varied parameters
                ffmpeg_cmd.extend([
                    '-c:a', 'aac',
                    '-b:a', uniqueness_params['audio_bitrate'],
                    '-ar', str(uniqueness_params['audio_sample_rate'])
                ])
                logger.info(f"ğŸ”Š éŸ³é¢‘é‡ç¼–ç : {uniqueness_params['audio_bitrate']} @ {uniqueness_params['audio_sample_rate']}Hz")
            else:
                # Copy audio without re-encoding
                ffmpeg_cmd.extend(['-c:a', 'copy'])

            # Add metadata randomization if uniqueness is enabled
            if enable_uniqueness:
                metadata_dict = uniqueness_params['metadata']
                ffmpeg_cmd.extend([
                    '-metadata', f"creation_time={metadata_dict['creation_time']}",
                    '-metadata', f"encoder={metadata_dict['encoder']}",
                    '-metadata', 'title=',
                    '-metadata', 'comment=',
                    '-map_metadata', '-1',
                ])
                logger.info(f"ğŸ·ï¸  å…ƒæ•°æ®æ¸…ç†å’ŒéšæœºåŒ–å®Œæˆ")

            ffmpeg_cmd.extend(['-y', output_file])

            logger.info(f"ğŸ¬ æ‰§è¡Œffmpegå‘½ä»¤: {' '.join(ffmpeg_cmd)}")

            # Run ffmpeg
            try:
                result = subprocess.run(
                    ffmpeg_cmd,
                    capture_output=True,
                    check=True
                )
                logger.info(f"âœ… ffmpegæ‰§è¡ŒæˆåŠŸ")

                # Verify output file
                if os.path.exists(output_file):
                    file_size = os.path.getsize(output_file)
                    logger.info(f"ğŸ“¦ è¾“å‡ºæ–‡ä»¶å¤§å°: {file_size / (1024*1024):.2f} MB")
            except subprocess.CalledProcessError as e:
                error_text = e.stderr.decode('utf-8', errors='ignore')
                logger.error(f"âŒ ffmpegæ‰§è¡Œå¤±è´¥:\n{error_text}")
                raise Exception(f"ffmpeg error: {error_text}")

        finally:
            # Clean up temporary ASS file
            if os.path.exists(ass_temp.name):
                logger.info(f"ğŸ—‘ï¸ åˆ é™¤ä¸´æ—¶ASSæ–‡ä»¶: {ass_temp.name}")
                os.unlink(ass_temp.name)

        logger.info(f"ğŸ‰ å¡æ‹‰OKå­—å¹•çƒ§å½•å®Œæˆ: {out_file.resolve()}")
        if enable_uniqueness:
            logger.info(f"âœ¨ è§†é¢‘å”¯ä¸€æ€§å¢å¼ºå·²åº”ç”¨")
        return str(out_file.resolve())

if __name__ == '__main__':
    file = '../../assets/video/test1.webm'
    subs_ai = SubsAI()
    model = subs_ai.create_model('openai/whisper', {'model_type': 'tiny'})
    subs = subs_ai.transcribe(file, model)
    subs.save('../../assets/video/test1.srt')
    subs2 = pysubs2.load('../../assets/video/test0-ar.srt')
    Tools.merge_subs_with_video({'English': subs, "Arabic": subs2}, file)
    # subs.save('test1.srt')
